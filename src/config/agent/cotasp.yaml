type: cotasp
actor:
    hidden_dims: [256, 256, 256]
    learning_rate: 3e-4
critic:
    hidden_dims: [256, 256, 256]
    learning_rate: 3e-4
temperature:
    init_temperature: 1.0
    learning_rate: 3e-4
theta_steps: 990
alpha_steps: 10
update_alpha: False # overrides ratio
target_entropy: null
backup_entropy: False
critic_reduction: min
tau: 0.005 # target network control
discount: 0.99 # discount factor