type: cotasp
actor:
    hidden_dims: [256, 256, 256]
    learning_rate: 3e-4
critic:
    hidden_dims: [256, 256, 256]
    learning_rate: 3e-4
temperature:
    init_temperature: 1.0
    learning_rate: 3e-4
dictionary:
    c: 1.0
    alpha: 1e-3
    method: lasso_lars
    positive_code: False
    scale_code: False
theta_steps: 990
alpha_steps: 10
update_alpha: False # overrides ratio
target_entropy: null
backup_entropy: False
critic_reduction: min
tau: 0.005 # target network control
discount: 0.99 # discount factor